{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 합성곱 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 합성곱/풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4차원 배열"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.rand(10, 1, 28, 28) # 무작위로 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 1, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 28, 28)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  8.13282329e-01,   6.73312756e-02,   4.20526758e-01,\n",
       "          8.91689829e-02,   2.84710747e-02,   9.13398248e-01,\n",
       "          5.28099866e-01,   5.72095376e-01,   1.31160355e-01,\n",
       "          7.92036378e-01,   5.43902077e-01,   1.19162578e-01,\n",
       "          9.77767591e-01,   4.59554460e-01,   6.22453600e-01,\n",
       "          1.84367548e-01,   7.47397825e-01,   2.45656688e-01,\n",
       "          3.76378763e-01,   5.56462537e-01,   3.44068223e-01,\n",
       "          4.81495858e-01,   3.93027313e-01,   6.75617911e-01,\n",
       "          7.26114981e-01,   3.03964314e-01,   8.96717426e-01,\n",
       "          4.24339163e-01],\n",
       "       [  2.69011741e-01,   2.99125716e-01,   5.60499628e-01,\n",
       "          6.75421478e-02,   7.01215911e-01,   5.56581929e-01,\n",
       "          2.39329646e-01,   9.59532708e-01,   1.26310603e-01,\n",
       "          1.81918772e-01,   2.80051614e-01,   3.79229260e-01,\n",
       "          1.58514488e-01,   6.42146686e-01,   2.13348393e-01,\n",
       "          7.51905406e-01,   6.48986778e-01,   1.73766652e-01,\n",
       "          4.09954154e-01,   2.18645129e-01,   3.89462664e-01,\n",
       "          4.69975012e-01,   1.51030307e-01,   1.80751979e-01,\n",
       "          4.74499277e-01,   6.07531107e-01,   4.34617510e-01,\n",
       "          3.17779795e-01],\n",
       "       [  7.30365387e-01,   9.65471808e-01,   5.59679154e-01,\n",
       "          8.55113029e-01,   1.41671744e-01,   6.76430085e-02,\n",
       "          1.55253669e-01,   4.16195841e-02,   4.60159979e-01,\n",
       "          4.84462257e-01,   4.19901445e-01,   3.25366798e-01,\n",
       "          2.27907272e-01,   1.97030555e-01,   7.71421366e-01,\n",
       "          2.73976539e-01,   2.98127431e-01,   6.41415710e-01,\n",
       "          8.87249752e-02,   2.75881094e-01,   7.81268908e-01,\n",
       "          6.82449371e-01,   7.51602128e-01,   6.96824827e-01,\n",
       "          3.71684827e-01,   7.71505946e-01,   3.77971115e-01,\n",
       "          4.62827698e-01],\n",
       "       [  7.96682020e-01,   3.26644854e-01,   8.68859252e-01,\n",
       "          6.60916671e-01,   4.15060807e-01,   8.40501121e-01,\n",
       "          6.73663198e-02,   9.73737672e-01,   7.20176365e-01,\n",
       "          3.23926086e-01,   8.12546889e-01,   5.81457130e-01,\n",
       "          5.56472121e-02,   3.53520114e-01,   5.59840963e-01,\n",
       "          1.18614873e-01,   3.79385332e-01,   8.29940897e-01,\n",
       "          1.99919706e-01,   1.63621864e-01,   2.54225553e-01,\n",
       "          1.07677828e-02,   1.71882566e-01,   6.30151993e-01,\n",
       "          5.00992660e-01,   6.97084617e-02,   7.62225261e-01,\n",
       "          9.62924920e-01],\n",
       "       [  9.68312330e-01,   6.54754513e-01,   5.51902191e-01,\n",
       "          3.70387725e-01,   3.45969723e-01,   1.97517664e-01,\n",
       "          8.12748272e-01,   9.97798192e-01,   4.51740254e-01,\n",
       "          7.74827796e-01,   4.10170549e-02,   2.57805218e-01,\n",
       "          4.38391078e-01,   4.47607307e-01,   1.78176340e-01,\n",
       "          2.07730590e-01,   4.55358252e-01,   3.54487062e-01,\n",
       "          2.12310193e-02,   7.47164497e-02,   8.99245918e-01,\n",
       "          5.72612067e-01,   8.25496284e-02,   2.14365863e-01,\n",
       "          5.16396021e-02,   5.92995274e-01,   2.98206102e-01,\n",
       "          7.62458056e-01],\n",
       "       [  9.35644146e-01,   8.16670717e-01,   4.65694951e-01,\n",
       "          3.40109157e-02,   1.11430532e-01,   2.59729640e-01,\n",
       "          9.67051789e-01,   6.44534844e-01,   9.53742713e-01,\n",
       "          1.14808947e-01,   2.89478709e-01,   5.07985668e-03,\n",
       "          3.96494797e-02,   9.84497249e-01,   5.61937532e-01,\n",
       "          3.02807507e-01,   5.39313965e-01,   9.69371278e-02,\n",
       "          2.55778901e-01,   7.94314261e-01,   8.33431490e-01,\n",
       "          6.59714315e-01,   6.20475784e-01,   5.04659581e-01,\n",
       "          2.21342780e-01,   7.72927302e-01,   9.61775215e-01,\n",
       "          1.31091929e-02],\n",
       "       [  4.70438288e-01,   8.44491492e-02,   9.79121594e-01,\n",
       "          9.36052653e-01,   8.04633404e-01,   8.30393563e-01,\n",
       "          7.34739510e-01,   8.05118360e-02,   1.83899302e-01,\n",
       "          7.13265068e-01,   5.79814355e-01,   8.73251617e-01,\n",
       "          1.84486631e-01,   3.81063607e-02,   2.44915768e-02,\n",
       "          7.36065495e-01,   2.83328032e-02,   7.14452490e-01,\n",
       "          9.20477740e-01,   4.12949514e-01,   8.60446133e-01,\n",
       "          5.87078953e-01,   3.83803939e-01,   1.79453821e-01,\n",
       "          4.09831017e-02,   2.67659690e-01,   1.33474143e-01,\n",
       "          3.31091959e-01],\n",
       "       [  4.04413862e-01,   6.12934864e-01,   6.87293663e-02,\n",
       "          1.75161770e-01,   2.89325455e-01,   9.52322438e-01,\n",
       "          1.69683779e-03,   1.21746236e-02,   8.40438650e-01,\n",
       "          7.86163004e-02,   4.44171851e-01,   8.61008076e-01,\n",
       "          8.27759537e-01,   3.72991924e-01,   3.18008737e-01,\n",
       "          3.02351935e-01,   4.58617152e-01,   3.56215321e-01,\n",
       "          9.21351951e-01,   8.92000326e-01,   8.29007312e-01,\n",
       "          1.62737080e-01,   3.11176609e-01,   1.62927423e-01,\n",
       "          8.78677169e-01,   7.18930060e-01,   1.60965310e-01,\n",
       "          4.29238522e-01],\n",
       "       [  8.90282654e-01,   5.79723975e-01,   6.81959427e-02,\n",
       "          4.26837726e-01,   6.12051824e-01,   7.38463260e-01,\n",
       "          6.39885091e-01,   1.00796795e-01,   6.55847917e-01,\n",
       "          9.14074499e-01,   3.97116495e-01,   8.38451647e-03,\n",
       "          8.69551218e-02,   7.99594809e-01,   6.73367465e-01,\n",
       "          1.85525417e-01,   2.71097333e-02,   5.35361204e-01,\n",
       "          7.26250497e-01,   2.62244620e-01,   6.61528441e-01,\n",
       "          6.62865354e-01,   5.79639541e-01,   7.44397817e-01,\n",
       "          6.55921504e-01,   5.00936858e-01,   9.27107711e-01,\n",
       "          9.16251737e-01],\n",
       "       [  3.36621628e-01,   3.81886182e-01,   3.38816585e-01,\n",
       "          7.16434110e-01,   9.32554622e-01,   8.51590757e-01,\n",
       "          8.21800440e-01,   5.83646268e-01,   8.72367917e-01,\n",
       "          5.75402882e-03,   9.12694015e-01,   7.64988116e-01,\n",
       "          7.39721966e-01,   3.51733659e-01,   8.74358274e-01,\n",
       "          2.19754601e-01,   2.83848271e-01,   2.12349001e-01,\n",
       "          9.18243874e-01,   6.56981510e-01,   8.01852526e-01,\n",
       "          1.81536574e-01,   7.29391102e-01,   2.56692911e-01,\n",
       "          1.85948219e-01,   1.63003090e-01,   5.86697433e-02,\n",
       "          5.64547354e-01],\n",
       "       [  4.13783267e-02,   5.69424998e-01,   6.24981167e-01,\n",
       "          9.16203794e-01,   2.43263107e-01,   6.65793232e-01,\n",
       "          1.30322956e-01,   1.30031827e-01,   8.72644274e-01,\n",
       "          8.27154662e-03,   5.36938023e-01,   6.41106779e-01,\n",
       "          8.83219471e-01,   3.43134427e-01,   1.30866019e-01,\n",
       "          3.40959283e-01,   8.46611861e-01,   1.14734128e-01,\n",
       "          2.60434353e-01,   3.45826506e-02,   6.89959844e-01,\n",
       "          8.11609620e-01,   9.69835540e-01,   2.79565799e-01,\n",
       "          8.64142716e-01,   8.59852233e-01,   9.45368151e-01,\n",
       "          1.41556130e-01],\n",
       "       [  7.02645571e-01,   8.80585177e-01,   4.88385962e-01,\n",
       "          8.47007272e-01,   8.16284876e-01,   9.19010847e-01,\n",
       "          2.37278371e-01,   8.31260874e-01,   4.74907286e-01,\n",
       "          1.96041999e-02,   1.89580209e-01,   8.73721055e-01,\n",
       "          9.40226860e-01,   8.08830182e-01,   3.19341693e-01,\n",
       "          8.71438784e-01,   3.72158757e-01,   8.33545671e-01,\n",
       "          3.06997772e-01,   5.19039274e-01,   8.13728335e-01,\n",
       "          5.80613316e-01,   7.94063762e-01,   6.57344220e-01,\n",
       "          1.50500801e-01,   3.80523027e-01,   8.56782607e-01,\n",
       "          5.03860092e-01],\n",
       "       [  9.59574593e-02,   3.44563347e-01,   3.50920766e-01,\n",
       "          5.59512589e-02,   9.83807416e-01,   7.90910221e-01,\n",
       "          1.99208307e-01,   5.22497984e-01,   1.07916375e-01,\n",
       "          2.39893547e-01,   5.68341548e-01,   2.83021577e-01,\n",
       "          6.41255358e-01,   2.30154221e-01,   2.85337175e-01,\n",
       "          7.78919217e-01,   6.77636154e-01,   9.66404282e-01,\n",
       "          7.12077085e-01,   1.67371682e-01,   8.08008626e-01,\n",
       "          3.46372254e-01,   6.30278773e-01,   5.65357095e-01,\n",
       "          6.59585232e-01,   8.42469025e-01,   1.02811845e-02,\n",
       "          6.79628402e-01],\n",
       "       [  5.02633764e-02,   7.81557951e-01,   7.64669000e-01,\n",
       "          3.26709736e-01,   4.26974773e-01,   7.49735514e-01,\n",
       "          5.26790891e-01,   6.58835291e-01,   1.54373697e-01,\n",
       "          7.24190112e-01,   3.48614812e-01,   9.53192309e-01,\n",
       "          7.16271183e-01,   2.72043671e-01,   4.87081238e-01,\n",
       "          6.78093327e-01,   4.10729087e-01,   6.67153643e-01,\n",
       "          5.81699831e-01,   5.71929170e-01,   1.84743146e-02,\n",
       "          8.92157530e-01,   5.76074495e-01,   7.90156411e-03,\n",
       "          4.54915767e-01,   6.37406737e-01,   1.93081692e-01,\n",
       "          7.17685182e-01],\n",
       "       [  5.04512549e-01,   3.45888650e-01,   6.31793245e-01,\n",
       "          4.70464642e-01,   6.83341231e-01,   9.52891973e-01,\n",
       "          8.57248840e-01,   1.74400390e-02,   5.94779811e-01,\n",
       "          5.06331241e-01,   2.97058889e-02,   8.03767159e-01,\n",
       "          9.12355884e-02,   4.45486135e-01,   8.60374028e-01,\n",
       "          8.87785475e-01,   5.95916176e-01,   7.63923905e-02,\n",
       "          2.52776989e-01,   1.41959886e-01,   4.13236889e-01,\n",
       "          7.79160221e-01,   2.86775195e-01,   2.44982763e-01,\n",
       "          8.59654418e-01,   4.23670389e-01,   2.18101398e-02,\n",
       "          3.85932888e-01],\n",
       "       [  4.67155193e-01,   4.09314830e-01,   6.20268678e-01,\n",
       "          7.62841097e-01,   2.04887179e-01,   9.58301153e-01,\n",
       "          2.67181931e-01,   7.16931058e-01,   6.66897284e-01,\n",
       "          4.56732309e-01,   3.56927928e-01,   6.70733084e-01,\n",
       "          3.11469166e-01,   9.45394371e-01,   3.40631282e-01,\n",
       "          1.75391555e-01,   1.55090789e-01,   6.30964282e-01,\n",
       "          5.53281164e-01,   6.30022075e-01,   8.64708105e-01,\n",
       "          5.71446801e-02,   5.39150028e-01,   4.89882691e-01,\n",
       "          9.05537946e-01,   7.83179795e-02,   9.85722060e-01,\n",
       "          4.55843996e-01],\n",
       "       [  6.42548254e-01,   5.05367825e-01,   4.78712223e-01,\n",
       "          5.10259926e-01,   1.18117627e-01,   9.18556601e-01,\n",
       "          3.47128780e-01,   3.36768479e-01,   3.35937054e-01,\n",
       "          1.03732308e-01,   3.23628832e-01,   7.89035533e-03,\n",
       "          3.64735981e-01,   3.01130920e-01,   5.91402531e-01,\n",
       "          7.99238242e-01,   7.97774174e-02,   4.87828535e-01,\n",
       "          9.84790992e-01,   6.79062615e-01,   3.71532833e-01,\n",
       "          8.10638303e-01,   7.13666238e-01,   8.69173559e-01,\n",
       "          9.07535466e-01,   8.15801730e-01,   2.03145250e-01,\n",
       "          3.73806801e-01],\n",
       "       [  6.00838898e-01,   3.22246540e-01,   8.45612096e-01,\n",
       "          2.38579538e-01,   3.47189696e-01,   4.37718028e-01,\n",
       "          8.72792354e-01,   7.78242225e-01,   8.52514523e-01,\n",
       "          5.77497660e-01,   4.73194418e-01,   5.34187514e-01,\n",
       "          3.43304515e-01,   1.29766294e-01,   2.46695482e-01,\n",
       "          2.91988444e-01,   9.23066807e-02,   7.41124740e-01,\n",
       "          9.50029916e-01,   1.65717642e-01,   1.03434564e-02,\n",
       "          3.49863659e-01,   8.93535354e-02,   2.02259530e-01,\n",
       "          4.11187494e-01,   9.73853205e-01,   9.60675004e-01,\n",
       "          6.43937597e-01],\n",
       "       [  8.55895403e-01,   7.22698040e-01,   2.69362833e-01,\n",
       "          7.29262500e-01,   8.94841693e-01,   6.21652422e-01,\n",
       "          1.82344304e-01,   5.22402297e-01,   8.38217623e-01,\n",
       "          4.28425880e-01,   7.14506827e-01,   7.04065298e-01,\n",
       "          9.90075230e-01,   7.86332226e-01,   8.00642659e-01,\n",
       "          5.97086223e-02,   7.55102590e-01,   9.25232530e-01,\n",
       "          9.33494714e-01,   8.71633718e-02,   6.77667870e-01,\n",
       "          7.44208906e-01,   1.35114005e-01,   3.82747812e-01,\n",
       "          7.65909685e-01,   1.34108221e-01,   9.75635770e-02,\n",
       "          3.73136111e-01],\n",
       "       [  7.69026920e-01,   8.50419240e-01,   6.09331446e-01,\n",
       "          9.87636774e-01,   4.98852652e-01,   9.65263230e-01,\n",
       "          7.12169640e-02,   4.06992785e-01,   1.32659625e-02,\n",
       "          8.60467616e-01,   7.34594535e-01,   2.78059025e-01,\n",
       "          5.92637243e-01,   6.61554566e-01,   1.12185744e-01,\n",
       "          4.05698706e-01,   1.12106858e-01,   5.23424411e-01,\n",
       "          3.69621654e-01,   7.71975388e-01,   2.64072516e-01,\n",
       "          8.48224199e-01,   8.83869885e-01,   8.67597825e-01,\n",
       "          1.71891842e-01,   9.16182891e-01,   4.99918804e-01,\n",
       "          2.57380981e-01],\n",
       "       [  2.68293589e-01,   8.21194268e-01,   1.43718858e-01,\n",
       "          1.21917084e-01,   2.67445973e-01,   7.81417211e-01,\n",
       "          2.37548715e-01,   7.41342973e-01,   7.11812605e-01,\n",
       "          2.99404195e-01,   7.87536615e-01,   5.69051258e-01,\n",
       "          6.09525982e-01,   8.64353319e-01,   9.85348916e-01,\n",
       "          4.63577769e-01,   6.55082449e-01,   2.07301425e-01,\n",
       "          2.92719781e-01,   3.19715615e-01,   3.08473496e-01,\n",
       "          3.51286726e-01,   2.19399219e-01,   7.19596630e-01,\n",
       "          4.02476252e-01,   4.88928174e-01,   2.12603321e-02,\n",
       "          4.15455743e-01],\n",
       "       [  1.10204470e-01,   8.80927301e-01,   9.74188810e-01,\n",
       "          4.10901928e-01,   6.21860890e-01,   4.85570456e-01,\n",
       "          8.51678059e-02,   5.18477315e-01,   1.27329688e-01,\n",
       "          3.32347636e-01,   5.72951714e-01,   6.10164429e-01,\n",
       "          4.00692040e-01,   2.42549836e-01,   5.56589104e-01,\n",
       "          3.99352201e-01,   9.25812468e-01,   8.43534347e-01,\n",
       "          1.07244688e-01,   7.99439325e-01,   7.58919526e-01,\n",
       "          1.10509825e-01,   6.08600432e-02,   8.66555614e-01,\n",
       "          3.02526722e-01,   8.27832667e-01,   2.82754744e-01,\n",
       "          5.00716796e-01],\n",
       "       [  7.42693701e-01,   1.59485491e-02,   8.53051553e-01,\n",
       "          3.93659698e-01,   9.84665976e-01,   4.60356800e-01,\n",
       "          2.95708065e-01,   5.70589812e-01,   5.43690576e-01,\n",
       "          5.89641716e-01,   8.83658974e-01,   5.88280283e-01,\n",
       "          7.24604200e-01,   1.85651878e-01,   2.24307699e-01,\n",
       "          4.81709357e-01,   5.57615653e-01,   6.37156226e-01,\n",
       "          2.14463490e-01,   3.46330421e-02,   6.91407453e-02,\n",
       "          3.32430647e-01,   7.45521424e-01,   8.62255531e-01,\n",
       "          1.00554219e-01,   7.22993959e-01,   3.94345790e-02,\n",
       "          2.09217401e-01],\n",
       "       [  8.37296826e-01,   6.46060729e-01,   6.30169087e-01,\n",
       "          9.09656473e-01,   5.08557256e-02,   7.52959456e-01,\n",
       "          6.45341281e-01,   1.06476715e-01,   6.38452435e-01,\n",
       "          9.55311670e-01,   4.17734330e-01,   6.00337394e-01,\n",
       "          4.18754226e-01,   4.45633916e-01,   8.38859680e-01,\n",
       "          3.64831330e-01,   9.81640970e-01,   7.01964613e-01,\n",
       "          3.45095360e-01,   2.60812657e-01,   8.98824290e-01,\n",
       "          6.64364266e-01,   5.70634537e-04,   1.57879559e-01,\n",
       "          6.15116470e-01,   8.34217672e-01,   1.06429798e-01,\n",
       "          1.24802358e-01],\n",
       "       [  4.98279432e-01,   7.26973132e-02,   9.61523165e-01,\n",
       "          3.42339802e-01,   8.39345777e-01,   4.48794608e-01,\n",
       "          9.01034209e-01,   2.30560022e-01,   8.72948905e-01,\n",
       "          5.54523830e-02,   8.83132118e-01,   9.97911533e-01,\n",
       "          8.53222708e-01,   2.45517130e-01,   7.67643811e-01,\n",
       "          5.99349571e-01,   3.10666692e-01,   6.66245075e-01,\n",
       "          8.26369900e-01,   5.19029918e-01,   4.02842843e-01,\n",
       "          5.69052641e-01,   9.75831236e-01,   7.86570395e-01,\n",
       "          2.36643246e-01,   9.29339022e-01,   6.92659997e-01,\n",
       "          3.08988013e-01],\n",
       "       [  6.95345215e-02,   7.15086748e-02,   1.42418870e-01,\n",
       "          3.05458840e-01,   9.95152953e-01,   2.20231718e-01,\n",
       "          6.51348834e-01,   8.98755356e-01,   9.83769651e-01,\n",
       "          3.60935676e-01,   4.87104877e-01,   9.65667501e-01,\n",
       "          6.60159248e-01,   8.73608496e-01,   2.56981307e-01,\n",
       "          1.62285860e-01,   8.37864328e-01,   1.16378869e-02,\n",
       "          3.49988667e-01,   6.50255752e-02,   4.90676055e-01,\n",
       "          6.07491447e-01,   5.22779706e-01,   2.72233174e-01,\n",
       "          1.67375689e-01,   5.27433337e-01,   4.54955670e-02,\n",
       "          8.54646459e-01],\n",
       "       [  2.15093961e-01,   7.36042957e-01,   4.71781212e-02,\n",
       "          3.79808232e-02,   9.99709083e-01,   1.22145609e-01,\n",
       "          3.68256200e-01,   3.20502989e-01,   7.96648657e-01,\n",
       "          3.04735068e-01,   5.86205711e-01,   4.98596437e-01,\n",
       "          6.13656747e-01,   6.49914310e-02,   9.45804107e-01,\n",
       "          5.02759789e-01,   6.08948477e-01,   6.67876664e-01,\n",
       "          1.97115661e-01,   9.70457147e-01,   9.58295711e-01,\n",
       "          1.26779193e-01,   8.40366919e-01,   4.43673481e-01,\n",
       "          9.85901568e-01,   4.21013259e-01,   6.54274105e-01,\n",
       "          3.55335079e-01],\n",
       "       [  4.61408085e-01,   9.21794580e-01,   5.28978117e-01,\n",
       "          1.50292249e-01,   8.17435770e-01,   1.59078002e-01,\n",
       "          6.62567639e-01,   9.55512312e-01,   1.85547267e-01,\n",
       "          6.62487274e-01,   4.46923870e-01,   9.56744509e-01,\n",
       "          7.66078752e-01,   4.27225131e-01,   8.93846077e-01,\n",
       "          2.35811527e-01,   4.97914437e-01,   4.77369140e-02,\n",
       "          8.48237898e-01,   7.94382236e-01,   4.89095433e-01,\n",
       "          9.41615690e-01,   3.31248430e-01,   3.48233977e-01,\n",
       "          7.53811576e-01,   6.82945136e-01,   3.39500544e-01,\n",
       "          3.40692637e-01]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 합성곱 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n",
      "(90, 75)\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)\n",
    "from common.util import im2col\n",
    "\n",
    "x1 = np.random.rand(1, 3, 7, 7) # (데이터 수, 채널 수, 높이, 너비)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad=0)\n",
    "print(col1.shape)\n",
    "\n",
    "x2 = np.random.rand(10, 3, 7, 7) # 데이터 10개\n",
    "col2 = im2col(x2, 5, 5, stride=1, pad=0)\n",
    "print(col2.shape) # (90, 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Convolution:\n",
    "    def __init__(self, W, b, stride=1, pad=0):\n",
    "        self.W = W\n",
    "        self.b = b\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        FN, C, FH, FW = self.W.shape\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H + 2*self.pad - FH) / self.stride)\n",
    "        out_w = int(1 + (W + 2*self.pad - FW) / self.stride)\n",
    "        \n",
    "        col = im2col(x, FH, FW, self.stride, self.pad)\n",
    "        col_W = self.W.reshape(FN, -1).T # 필터 전개\n",
    "        out = np.dot(col, col_W) + self.b\n",
    "        \n",
    "        out = out.reshape(N, out_h, out_w, -1).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 풀링 계층 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Pooling:\n",
    "    def __init__(self, pool_h, pool_w, stride=1, pad=0):\n",
    "        self.pool_h = pool_h\n",
    "        self.pool_w = pool_w\n",
    "        self.stride = stride\n",
    "        self.pad = pad\n",
    "        \n",
    "    def forward(self, x):\n",
    "        N, C, H, W = x.shape\n",
    "        out_h = int(1 + (H - self.pool_h) / self.stride)\n",
    "        out_w = int(1 + (W - self.pool_w) / self.stride)\n",
    "        \n",
    "        # 전개 (1)\n",
    "        col = im2col(x, self.pool_h, self.pool_w, self.stride, self.pad)\n",
    "        col = col.reshape(-1, self.pool_h * self.pool_w)\n",
    "        \n",
    "        # 최댓값(2)\n",
    "        out = np.max(col, axis=1)\n",
    "        \n",
    "        # 성형 (3)\n",
    "        out = outl.reshape(N, out_h, out_w, C).transpose(0, 3, 1, 2)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import pickle\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "from common.layers import *\n",
    "from common.gradient import numerical_gradient\n",
    "\n",
    "\n",
    "class SimpleConvNet:\n",
    "    \"\"\"단순한 합성곱 신경망\n",
    "    \n",
    "    conv - relu - pool - affine - relu - affine - softmax\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    input_size : 입력 크기（MNIST의 경우엔 784）\n",
    "    hidden_size_list : 각 은닉층의 뉴런 수를 담은 리스트（e.g. [100, 100, 100]）\n",
    "    output_size : 출력 크기（MNIST의 경우엔 10）\n",
    "    activation : 활성화 함수 - 'relu' 혹은 'sigmoid'\n",
    "    weight_init_std : 가중치의 표준편차 지정（e.g. 0.01）\n",
    "        'relu'나 'he'로 지정하면 'He 초깃값'으로 설정\n",
    "        'sigmoid'나 'xavier'로 지정하면 'Xavier 초깃값'으로 설정\n",
    "    \"\"\"\n",
    "    def __init__(self, input_dim=(1, 28, 28), \n",
    "                 conv_param={'filter_num':30, 'filter_size':5, 'pad':0, 'stride':1},\n",
    "                 hidden_size=100, output_size=10, weight_init_std=0.01):\n",
    "        filter_num = conv_param['filter_num']\n",
    "        filter_size = conv_param['filter_size']\n",
    "        filter_pad = conv_param['pad']\n",
    "        filter_stride = conv_param['stride']\n",
    "        input_size = input_dim[1]\n",
    "        conv_output_size = (input_size - filter_size + 2*filter_pad) / filter_stride + 1\n",
    "        pool_output_size = int(filter_num * (conv_output_size/2) * (conv_output_size/2))\n",
    "\n",
    "        # 가중치 초기화\n",
    "        self.params = {}\n",
    "        self.params['W1'] = weight_init_std * \\\n",
    "                            np.random.randn(filter_num, input_dim[0], filter_size, filter_size)\n",
    "        self.params['b1'] = np.zeros(filter_num)\n",
    "        self.params['W2'] = weight_init_std * \\\n",
    "                            np.random.randn(pool_output_size, hidden_size)\n",
    "        self.params['b2'] = np.zeros(hidden_size)\n",
    "        self.params['W3'] = weight_init_std * \\\n",
    "                            np.random.randn(hidden_size, output_size)\n",
    "        self.params['b3'] = np.zeros(output_size)\n",
    "\n",
    "        # 계층 생성\n",
    "        self.layers = OrderedDict()\n",
    "        self.layers['Conv1'] = Convolution(self.params['W1'], self.params['b1'],\n",
    "                                           conv_param['stride'], conv_param['pad'])\n",
    "        self.layers['Relu1'] = Relu()\n",
    "        self.layers['Pool1'] = Pooling(pool_h=2, pool_w=2, stride=2)\n",
    "        self.layers['Affine1'] = Affine(self.params['W2'], self.params['b2'])\n",
    "        self.layers['Relu2'] = Relu()\n",
    "        self.layers['Affine2'] = Affine(self.params['W3'], self.params['b3'])\n",
    "\n",
    "        self.last_layer = SoftmaxWithLoss()\n",
    "\n",
    "    def predict(self, x):\n",
    "        for layer in self.layers.values():\n",
    "            x = layer.forward(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def loss(self, x, t):\n",
    "        \"\"\"손실 함수를 구한다.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        \"\"\"\n",
    "        y = self.predict(x)\n",
    "        return self.last_layer.forward(y, t)\n",
    "\n",
    "    def accuracy(self, x, t, batch_size=100):\n",
    "        if t.ndim != 1 : t = np.argmax(t, axis=1)\n",
    "        \n",
    "        acc = 0.0\n",
    "        \n",
    "        for i in range(int(x.shape[0] / batch_size)):\n",
    "            tx = x[i*batch_size:(i+1)*batch_size]\n",
    "            tt = t[i*batch_size:(i+1)*batch_size]\n",
    "            y = self.predict(tx)\n",
    "            y = np.argmax(y, axis=1)\n",
    "            acc += np.sum(y == tt) \n",
    "        \n",
    "        return acc / x.shape[0]\n",
    "\n",
    "    def numerical_gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다（수치미분）.\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        loss_w = lambda w: self.loss(x, t)\n",
    "\n",
    "        grads = {}\n",
    "        for idx in (1, 2, 3):\n",
    "            grads['W' + str(idx)] = numerical_gradient(loss_w, self.params['W' + str(idx)])\n",
    "            grads['b' + str(idx)] = numerical_gradient(loss_w, self.params['b' + str(idx)])\n",
    "\n",
    "        return grads\n",
    "\n",
    "    def gradient(self, x, t):\n",
    "        \"\"\"기울기를 구한다(오차역전파법).\n",
    "        Parameters\n",
    "        ----------\n",
    "        x : 입력 데이터\n",
    "        t : 정답 레이블\n",
    "        Returns\n",
    "        -------\n",
    "        각 층의 기울기를 담은 사전(dictionary) 변수\n",
    "            grads['W1']、grads['W2']、... 각 층의 가중치\n",
    "            grads['b1']、grads['b2']、... 각 층의 편향\n",
    "        \"\"\"\n",
    "        # forward\n",
    "        self.loss(x, t)\n",
    "\n",
    "        # backward\n",
    "        dout = 1\n",
    "        dout = self.last_layer.backward(dout)\n",
    "\n",
    "        layers = list(self.layers.values())\n",
    "        layers.reverse()\n",
    "        for layer in layers:\n",
    "            dout = layer.backward(dout)\n",
    "\n",
    "        # 결과 저장\n",
    "        grads = {}\n",
    "        grads['W1'], grads['b1'] = self.layers['Conv1'].dW, self.layers['Conv1'].db\n",
    "        grads['W2'], grads['b2'] = self.layers['Affine1'].dW, self.layers['Affine1'].db\n",
    "        grads['W3'], grads['b3'] = self.layers['Affine2'].dW, self.layers['Affine2'].db\n",
    "\n",
    "        return grads\n",
    "        \n",
    "    def save_params(self, file_name=\"params.pkl\"):\n",
    "        params = {}\n",
    "        for key, val in self.params.items():\n",
    "            params[key] = val\n",
    "        with open(file_name, 'wb') as f:\n",
    "            pickle.dump(params, f)\n",
    "\n",
    "    def load_params(self, file_name=\"params.pkl\"):\n",
    "        with open(file_name, 'rb') as f:\n",
    "            params = pickle.load(f)\n",
    "        for key, val in params.items():\n",
    "            self.params[key] = val\n",
    "\n",
    "        for i, key in enumerate(['Conv1', 'Affine1', 'Affine2']):\n",
    "            self.layers[key].W = self.params['W' + str(i+1)]\n",
    "            self.layers[key].b = self.params['b' + str(i+1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== epoch:1, train acc:0.176, test acc:0.155 ===\n",
      "=== epoch:2, train acc:0.954, test acc:0.956 ===\n",
      "=== epoch:3, train acc:0.981, test acc:0.974 ===\n",
      "=== epoch:4, train acc:0.976, test acc:0.975 ===\n",
      "=== epoch:5, train acc:0.984, test acc:0.976 ===\n",
      "=== epoch:6, train acc:0.984, test acc:0.983 ===\n",
      "=== epoch:7, train acc:0.989, test acc:0.987 ===\n",
      "=== epoch:8, train acc:0.986, test acc:0.98 ===\n",
      "=== epoch:9, train acc:0.991, test acc:0.981 ===\n",
      "=== epoch:10, train acc:0.993, test acc:0.988 ===\n",
      "=== epoch:11, train acc:0.996, test acc:0.988 ===\n",
      "=== epoch:12, train acc:0.994, test acc:0.989 ===\n",
      "=== epoch:13, train acc:0.997, test acc:0.989 ===\n",
      "=== epoch:14, train acc:0.997, test acc:0.989 ===\n",
      "=== epoch:15, train acc:0.997, test acc:0.988 ===\n",
      "=== epoch:16, train acc:0.999, test acc:0.987 ===\n",
      "=== epoch:17, train acc:0.998, test acc:0.987 ===\n",
      "=== epoch:18, train acc:0.997, test acc:0.989 ===\n",
      "=== epoch:19, train acc:0.999, test acc:0.989 ===\n",
      "=== epoch:20, train acc:0.999, test acc:0.986 ===\n",
      "=============== Final Test Accuracy ===============\n",
      "test acc:0.9893\n",
      "Saved Network Parameters!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nnP8PSRUbFi7TIxwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1048c5240>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)  # 부모 디렉터리의 파일을 가져올 수 있도록 설정\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataset.mnist import load_mnist\n",
    "from common.trainer import Trainer\n",
    "\n",
    "# 데이터 읽기\n",
    "(x_train, t_train), (x_test, t_test) = load_mnist(flatten=False)\n",
    "\n",
    "# 시간이 오래 걸릴 경우 데이터를 줄인다.\n",
    "#x_train, t_train = x_train[:5000], t_train[:5000]\n",
    "#x_test, t_test = x_test[:1000], t_test[:1000]\n",
    "\n",
    "max_epochs = 20\n",
    "\n",
    "network = SimpleConvNet(input_dim=(1,28,28), \n",
    "                        conv_param = {'filter_num': 30, 'filter_size': 5, 'pad': 0, 'stride': 1},\n",
    "                        hidden_size=100, output_size=10, weight_init_std=0.01)\n",
    "                        \n",
    "trainer = Trainer(network, x_train, t_train, x_test, t_test,\n",
    "                  epochs=max_epochs, mini_batch_size=100,\n",
    "                  optimizer='Adam', optimizer_param={'lr': 0.001},\n",
    "                  evaluate_sample_num_per_epoch=1000)\n",
    "trainer.train()\n",
    "\n",
    "# 매개변수 보존\n",
    "network.save_params(\"params.pkl\")\n",
    "print(\"Saved Network Parameters!\")\n",
    "\n",
    "# 그래프 그리기\n",
    "markers = {'train': 'o', 'test': 's'}\n",
    "x = np.arange(max_epochs)\n",
    "plt.plot(x, trainer.train_acc_list, marker='o', label='train', markevery=2)\n",
    "plt.plot(x, trainer.test_acc_list, marker='s', label='test', markevery=2)\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.ylim(0, 1.0)\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
